from sklearn.linear_model import LogisticRegression
import joblib

# 准备输入变量和输出变量
X = [[0.5833333333333334, 0.0, 0.25, 0.0], [4.333333333333333, 0.0, 6.25, 0.25], [2.5555555555555554, 2.25, 0.25, 4.0], [0.5555555555555556, 0.25, 0.25, 1.0], [2.2222222222222223, 1.0, 1.0, 4.0], [2.5555555555555554, 4.0, 0.25, 2.25], [3.6666666666666665, 0.25, 0.0, 6.25], [13.805555555555555, 9.0, 0.0, 0.25], [46.47222222222222, 4.0, 72.25, 1.0], [1.8888888888888886, 0.25, 1.0, 0.25], [2.222222222222222, 4.0, 1.0, 1.0], [1.8055555555555556, 1.0, 2.25, 0.0], [2.888888888888889, 0.25, 0.0, 6.25], [2.5555555555555554, 1.0, 4.0, 0.0], [1.8888888888888886, 2.25, 2.25, 1.0], [1.8888888888888886, 2.25, 0.0, 0.25], [15.666666666666666, 9.0, 16.0, 4.0], [2.472222222222222, 2.25, 1.0, 4.0], [4.916666666666667, 1.0, 0.0, 12.25], [4.222222222222222, 4.0, 4.0, 4.0], [4.888888888888888, 4.0, 1.0, 9.0], [0.8055555555555557, 0.25, 0.0, 1.0], [3.3333333333333335, 0.25, 2.25, 4.0], [2.222222222222222, 1.0, 4.0, 1.0], [2.4722222222222214, 6.25, 0.25, 0.25], [2.222222222222222, 1.0, 4.0, 1.0], [2.5555555555555554, 0.0, 4.0, 1.0], [1.6666666666666667, 1.0, 4.0, 0.0], [4.222222222222222, 0.25, 4.0, 6.25], [15.25, 1.0, 1.0, 30.25], [15.555555555555557, 25.0, 4.0, 9.0], [49.333333333333336, 9.0, 100.0, 1.0], [3.555555555555556, 4.0, 0.0, 4.0], [1.8888888888888886, 0.0, 0.0, 1.0], [2.25, 0.25, 2.25, 2.25], [2.222222222222222, 4.0, 1.0, 1.0], [1.3333333333333333, 0.25, 0.0, 0.25], [0.8888888888888888, 0.25, 1.0, 0.25], [2.5555555555555554, 1.0, 4.0, 0.0], [13.916666666666666, 4.0, 2.25, 16.0], [4.333333333333333, 6.25, 1.0, 2.25], [1.5833333333333333, 1.0, 2.25, 1.0], [17.0, 9.0, 36.0, 0.0], [2.4722222222222223, 0.0, 0.0, 2.25], [1.5833333333333333, 2.25, 0.25, 2.25], [31.333333333333332, 12.25, 9.0, 72.25], [7.333333333333333, 12.25, 0.25, 9.0], [2.222222222222222, 4.0, 0.25, 2.25], [105.22222222222221, 81.0, 132.25, 90.25], [4.0, 0.0, 4.0, 0.0], [3.8888888888888893, 1.0, 4.0, 4.0], [75.80555555555556, 81.0, 0.25, 144.0], [2.222222222222222, 1.0, 4.0, 1.0], [1.4722222222222225, 0.25, 4.0, 0.0], [114.47222222222224, 132.25, 144.0, 9.0], [3.0, 4.0, 1.0, 4.0], [2.5555555555555554, 0.25, 2.25, 4.0], [118.25, 90.25, 9.0, 0.0], [3.805555555555556, 6.25, 1.0, 4.0], [2.5555555555555554, 2.25, 0.25, 4.0], [0.0, 0.0, 0.0, 0.0], [34.55555555555556, 1.0, 9.0, 49.0], [2.25, 2.25, 0.25, 2.25], [10.333333333333334, 0.0, 4.0, 9.0], [1.3333333333333333, 2.25, 1.0, 0.25], [4.888888888888888, 4.0, 0.25, 0.25], [1.888888888888889, 0.25, 4.0, 0.25], [3.555555555555556, 4.0, 0.0, 4.0], [1.8888888888888886, 2.25, 2.25, 1.0], [3.472222222222222, 4.0, 2.25, 4.0], [2.9166666666666665, 2.25, 1.0, 4.0], [4.222222222222222, 4.0, 4.0, 0.0], [1.8888888888888886, 2.25, 1.0, 2.25], [29.222222222222232, 49.0, 4.0, 0.0], [0.9166666666666666, 0.0, 2.25, 0.0], [2.5555555555555554, 0.25, 4.0, 0.25], [2.0, 0.0, 2.25, 2.25], [13.888888888888888, 20.25, 9.0, 0.25], [1.8888888888888886, 1.0, 0.25, 2.25], [14.472222222222221, 12.25, 1.0, 25.0], [2.5555555555555554, 4.0, 0.25, 2.25], [23.222222222222225, 30.25, 30.25, 1.0], [2.5555555555555554, 4.0, 2.25, 0.25], [31.222222222222225, 42.25, 9.0, 42.25], [1.9166666666666667, 0.0, 4.0, 0.25], [55.25, 64.0, 64.0, 0.25], [3.472222222222222, 4.0, 4.0, 2.25], [50.13888888888889, 4.0, 30.25, 81.0], [3.4722222222222228, 6.25, 0.0, 4.0], [50.88888888888889, 20.25, 0.0, 20.25], [3.4722222222222228, 2.25, 4.0, 4.0], [63.25, 56.25, 0.0, 64.0], [1.9166666666666667, 0.25, 4.0, 0.0], [97.58333333333333, 0.0, 90.25, 64.0], [1.8055555555555554, 0.25, 2.25, 2.25], [106.80555555555559, 4.0, 6.25, 0.0], [1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0], [1.222222222222222, 0.0, 1.0, 0.0], [77.47222222222223, 90.25, 0.0, 0.0], [1.25, 0.0, 1.0, 2.25], [63.13888888888889, 4.0, 100.0, 0.25], [6.888888888888888, 4.0, 0.0, 16.0], [20.583333333333332, 16.0, 20.25, 25.0], [27.472222222222218, 30.25, 16.0, 36.0], [21.88888888888889, 42.25, 6.25, 9.0], [39.88888888888889, 20.25, 0.0, 56.25], [34.13888888888889, 2.25, 64.0, 0.0], [26.805555555555557, 0.0, 20.25, 0.0], [48.13888888888889, 0.0, 4.0, 90.25], [44.583333333333336, 72.25, 25.0, 0.0], [83.8888888888889, 81.0, 0.0, 0.0], [108.55555555555554, 90.25, 110.25, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]  # 输入变量
y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]
# 输出变量

# 创建逻辑回归模型
model = LogisticRegression()

# 拟合模型
model.fit(X, y)

# 保存模型到文件
joblib.dump(model, 'model.pkl')
